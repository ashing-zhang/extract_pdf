Vision-Based Automatic Groceries Tracking 
System - Smart Homes 
Divya Mereddy 
Computer Science 
University Of Cincinnati 
Cincinnati, OH 
mereddda@mail.uc.edu 
Abstract— With advanced AI, while every industry is growing at  storage space. Sometimes one fruit or piece of fruit can be 
rocket speed, the smart home industry has not reached the next- stored in multiple places within refrigerator. Predicting the 
generation. There is still a huge leap of innovation that needs to  needs  of  the  user  is  also  a  big  problem  but  definitely 
happen before we call a home a ‘Smart home’. A Smart home  predictable using a supply chain system[9], user inputs, and 
should predict residents' needs and fulfill them in a timely manner. 
interest prediction systems[8]. A grocery tracking model is an 
One of the important tasks of maintaining a home is timely grocery 
AI  asset  that  provides  an  enhanced  level  of  automation 
tracking and supply maintenance. Grocery tracking models are 
without the need for human input. This can be done through 
very famous in the retail industry but they are nonexistent in the 
a combination of sensors [1],[2], and vision[4], which are 
common  household.  Groceries  detection  in  household 
able to collect data based on the location, movement, and 
refrigerators or storage closets is very complicated compared to 
status of a given asset. This data is then fed into an AI system 
retail shelving data. In this paper,  home grocery tracking problem 
that uses predictive modeling to generate real-time updates of 
is resolved by combining retail shelving data and fruits dataset 
each asset quantity. In our paper, we are developing home 
with real-time 360 view data points collected from home groceries 
grocery tracking system using computer vision.  
storage. By integrating this vision-based object detection system 
along with supply chain and user food interest prediction systems, 
II.RESEARCH IN INDUSTRY 
complete automation of groceries ordering can be achieved.  
   Overall  the  current  research  in  this  domain  is  still 
Keywords—Automatic grocery tracking system, Grocery supply  unsaturated,  showing  immense  potential  for  future 
chain, Smart home, YOLO, Smart Grocery ordering system  developments.,  particularly  in  vision-based  applications, 
such as home grocery tracking. [1] has developed a similar 
I.INTRODUCTION (HEADING 1) 
project centered around prelabeled boxes and their respective 
   In recent years, there has been a huge growth in the world  weights.  
of intelligent devices for home automation. Such gadgets are 
A.  Smart grocery tracking systems based on sensors  
designed in order to ease the interaction between people and 
daily home duties. As both AI and smart home technologies    A team from JEC Jabalpur M. P, India [1] has developed 
advance, more use cases emerge. It seems as though more  groceries track systems based on the weight of the box. But 
possibilities present themselves for home automation, so it’s  their functionalities are very limited. Different goods cannot 
exciting to see how they can make life easier for homeowners  be combined. We can find similar research from some other 
using applications like smart closets, grocery tracking, food  institutes [2][3]. 
suggestions etc. With lack of drastic advancement in smart 
B.  Refrigerator Industry 
home AI systems, we still see human efforts that could be 
   In the refrigerator industry, prominent companies such as 
spent elsewhere. Automating such repetitive tasks might free 
Samsung,  LG,  and  others  have  made  commitments  to 
up more time and give out more efficient results. 
introduce smart features in their products [5].  While some 
Today, we can find that the majority of similar tasks are  progress has been made in this direction, certain features still 
already  automated  in  AI  industry.  But  we  do  not  see  a  await  automation,  and  specific  aspects  of  research, 
collaborated automation of such tasks in household activities  particularly in groceries tracking, are yet to be initiated. As a 
implemented  effectively.  Groceries  tracking  systems  are  result, achieving a fully automated groceries tracking system 
already  implemented  in  retail  stores.    Similar  remains an elusive goal. 
implementations can be introduced in household activities 
C.  Store Groceries Tracking 
and modified to suit household usage. The major challenge 
with this implementation is object detection for complicated     As mentioned previously, home groceries tracking is very 
refrigerator.  similar to a store grocery tracking system. In-store grocery 
tracking domain, extensive research[4] is going on. But these 
   Store groceries shelving tracking is well organized. It's 
techniques  are  not  implemented  in  more  complex  home 
therefore easy to track though the amount of goods is high. 
groceries system yet.  
When it comes to a      groceries closet or refrigerator, it is 
very complicated because it’s very unorganized, and small     This  project  does  not  concentrate  on  the  sensors 
quantities  can  be  stored  in  multiple  locations  within  the  technique. In our paper, we present an innovative approach 
XXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEE 

utilizing the newly created refrigerator dataset[10] specially  explained above in our user case we need basic items like 
curated for this purpose: the implementation of YOLO for a  veggies, milk, water etc.  
smart  home  application.  Although  the  task  of  grocery 
B.  Available data 
shelfing prediction for common households is more intricate 
than store groceries, we have successfully developed a unique     We can get the information from the groceries database. 
model tailored to address this complexity.  So we tried to utilize open-source grocery tracking data using 
Recognition of supermarket products using Computer Vision 
III.BACKGROUND  publication [2].  
 Groceries tracking system is a part of smart home and it 
1.  Fruits 360 dataset[11]: A dataset of images containing 
mainly integrates with food suggestions system and supply 
fruits and vegetables. It contains different types of fruits and 
chain  grocery  ordering  system.  AI  food  suggestions 
vegetables  (including  different  varieties)  like  Apples, 
system[8]  provides automated food suggestions to users and 
Apricot, Avocado, Avocado ripe, Banana, and many more. 
integrates  the  user-selected  food  menu  with  the  complete 
But we considered only the items we are tracking shown in 
smart home system to predict the goods' needs.  AI-based 
Table 1 Tracking Groceries List. It has a total Number of 
supply  chain  system[9]  predicts  the  needs  of  users  and 
classes: 131 (fruits and vegetables) of image size: 100x100 
integrate with grocery tracking systems. For this project, we 
pixels. 
developed  a  grocery  tracking  system  for  a  basic  weekly 
schedule of one person. It's a simple week plan with few 
repeated items as explained below. 
As this problem was not researched before but again similar 
to a few industry-famous groceries tracking models, some of 
the existing data along with custom-built data was used. This 
project predicts the basic need of single user. It's an attempt 
to validate whether advanced AI systems are positioned to 
fulfill the needs of a human in simple user case. 
 
Considering below as the list of the groceries user prefer to 
have in his refrigerator every day, in this project we will track 
them only.   
TABLE I.   TRACKING GROCERIES LIST 
  Groceries  
1  Banana  Fig. 1.  Fruits 360 Dataset 
2  Avacado  2.  Groceries tracking data set [12] SKU110:  
3  Milk 
 
4  Strawberries 
5  Blueberries 
6  tamatos 
7  carrots 
8  Salad Mix 
9  egg white  
IV.DATA SOURCES 
   As this topic has not been researched before, new real-
time  data  creation  was  needed.  However,  existing  data 
sources are utilized to train our deep learning models, and 
real-time data created from the project environment is also 
utilized to customize the model predictions to this use case. 
Custom-created  data  has  improved  the  efficiency  of  the 
model significantly.  
Fig. 2.  Store tracking data - SKU110k dataset 
A.  Needed data 
SKU110k dataset is based on images of retail objects in a 
  We need a large amount of image data of every single  densely packed setting. It provides training, validation and 
piece of grocery we can ever find in a refrigerator. The user  test set images and the corresponding .csv files which contain 
case that we are considering in this paper is simple as shown  information for bounding box locations of all objects in those 
in the Tracking Groceries list. We need minimum data that  images. The .csv files have object bounding box information 
represent this list. To list them, we need fruits, vegetables,  written in the following columns:  image_name,x1,y1,x2,y2, 
different brands of food products, milk, and many more. As  class,image_width,image_height  where  x1,y1  are  top  left 
coordinates  of  bounding  box  and  x2,y2  are  bottom  right 

|    | Groceries    |
|---:|:-------------|
|  1 | Banana       |
|  2 | Avacado      |
|  3 | Milk         |
|  4 | Strawberries |
|  5 | Blueberries  |
|  6 | tamatos      |
|  7 | carrots      |
|  8 | Salad Mix    |
|  9 | egg white    |

coordinates  of  bounding  box,  rest  of  parameters  are  self- Groceries  List.    we  utilized  Roboflow[14]  for  labeling 
explanatory.    unlabeled data. The final data dataset is this located at [10].   
An  example  of  parameters  of  train_0.jpg  image  for  one   
bounding box, is shown below. There are several bounding 
boxes  for  each  image,  one  box  for  each  object.  We  also   
aggregated [22] data set, consisting of the images of the shelf 
of the grocery store and annotations of the bounding boxes in 
 
the form of text files. 
C.  Data sets needed to create (custom dataset)   
Though  the  previously  openly  available  data  sets  we 
considered  are  capturing  fruits,  vegetables,  and  groceries,   
they don't represent the home refrigerator/ groceries closet 
 
data.  Home  grocery  storage  system  is  complicated  and 
messy. In addition, as the Fruits 360 dataset doesn't have  Fig. 3.  Custom refrigerator/ closet groceries dataset  
object localization, the model was not able to predict multi 
 
outputs. The groceries dataset has all types of tracking items 
along with localization but, as discussed before, groceries 
V.MODEL BUILDING 
data is very well organized compared to the home groceries 
dataset, which makes it difficult to predict accurately. To   
solve this problem,  we needed to create real-time data to 
A.  Complexities & Challenges 
improve  the  performance  of  our  model  to  predict  the 
groceries in the refrigerator/closet accurately. To improve the  While this problem is similar to store-based grocery tracking 
dataset size and add additional capabilities to the model, like  and fruit object detection, to achieve good accuracy we had 
detecting  objects  from  blurred  veggies,    we  used  data  to resolve the below complexities which are not present in 
augmentation steps. We created more data using rotating,  either store-based grocery tracking or fruit object detection.   
zooming techniques, and more as shown below. 
1.  One of the main complexity of the project is that 
Preprocessing:  none of the openly available data represents the use 
case.  
Auto-Orient: Applied 
2.  Capturing  the  complex  common  man 
Resize: Stretch to 640x640 
refrigerator/ groceries closet data through images is 
Augmentations:   difficult. As the common man tends to save his groceries 
in  small  amounts  throughout  their  refrigerator 
Outputs per training example: 3 
(sometimes throughout their kitchen space).  
Flip: Horizontal 
3.  The shelves are typically cluttered and often not 
Rotation: Between -15° and +15°  organized in a regular fashion. 
4.  Ideal images of different products available to 
Grayscale: Apply to 25% of images 
the  vision  system  are  often  taken  using  different 
Hue: Between -25° and +25° 
cameras  resulting  in  different  distributions  of  image 
Saturation: Between -25% and +25%  intensities.  
5.  Also, due to different imaging parameters, the 
Exposure: Between -25% and +25% 
length of the product (in some units of length, say, cm) 
Blur: Up to 2.5px 
is mapped to different pixel resolutions for the product 
Mosaic: Applied  and shelf.  
Bounding Box: Shear: ±15° Horizontal, ±15° Vertical  B.  Model Development 
Bounding Box: Exposure: Between -25% and +25%   
We  can  leverage  vision  models  to  gather  information  by 
Bounding Box: Noise: Up to 5% of pixels 
employing  micro  cameras  strategically  placed  inside  the 
This  dataset  is  created  from  our  research  environment  to  refrigerator at multiple locations. These cameras can capture 
customize the model predictions for this use case. In addition  images from various angles, allowing us to comprehensively 
to the custom dataset created, we also included open-sourced  assess the contents and overall condition of the refrigerator. 
refrigerator image data to capture refrigerator storage pictures  Consequently,  we  can  obtain  a  holistic  view  of  the 
based on the keywords method.    refrigerator's contents and generate an accurate grocery list 
based  on  the  captured  data.  The  utilization  of  multiple 
As mentioned [13] article, we also tried to create synthetic 
cameras,  along  with  their  ability  to  capture  multi-angle 
data based on a video that covers a 360 degrees view of a 
pictures, has proven to be immensely valuable. This approach 
product.  It  helped  us  with  the  dataset  size  and  helped  to 
improve accuracy. We considered sub-data from all datasets  has greatly enhanced our capability to capture view of the 
mentioned above such that it can represent Table 1  Tracking  refrigerator's  contents.  We  developed  two  systems  using 
ResNet[15] and YOLO[16].  

  specific to refrigerator storage keywords, as well as custom-
built data generated from real-time experiment environments. 
1.  ResNet Model: 
To  facilitate  the  process  of  label  creation  and  data 
augmentation, Roboflow was utilized. The inclusion of both 
For the initial training phase, we utilized the fruits360  dataset. 
the fruits dataset and retail shelf dataset provided the model 
The  development  of  our  model  involved  leveraging  the 
with the ability to predict fruits and groceries effectively. 
power  of  ResNet  networks.  We  have  extended  [17]  fruit 
However, to further enhance the model's understanding of the 
detection based on Fruits 360 dataset. As described this type 
environment, we incorporated customized images, keyword-
of network makes use of convolutional layers, pooling layers, 
based images, and 360-view(based on [13]) pictures. This 
ReLU  layers,  fully  connected  layers,  and  loss  layers. 
additional data allowed the model to gain a comprehensive 
Utilizing  the  ResNet  architecture,  we  successfully 
360-degree  perspective,  resulting  in  significant 
implemented fruit detection and classification, enabling us to 
improvements(6%) in its predictive accuracy. 
assign relevant tags to each item. It was able to detect only 
 
single fruit(grocery item) at a time as shown in Fig 5. Because 
 
of the nature of the training data, the model was able to detect 
 
objects properly if there is only a single item in the complete 
 
input picture. To utilize this in real-time data we need to break 
down  the  whole  storage  into  individual  items  and  make 
predictions.  Instead  of  this,  we  can  also  achieve  similar 
results with multiple models or architecture changes to detect 
multi items. However, as the number of items to detect grew, 
the complexity of the system increases significantly. Instead 
of opting for these complicated methods, we went with an 
alternative approach by adopting an object-localized data-
based multi-object detection model. This decision was made 
to overcome the challenges posed by a larger number of items, 
ensuring improved accuracy and efficiency in the detection 
and classification process. 
 
       
Fig. 4.   ResoNet – Model Predictions  
Fig. 5.  Data Sources And Process Flow 
 
2.  Model  Improvements  -  Object  localization  data  with  The  implemented  model  showcases  both  simplicity  and 
YOLO:  innovation. YOLO models have become commonplace in the 
industry,  particularly  for  groceries  detection  in  the  retail 
Furthermore, it is important to note that the dataset used for 
domain. However, the application of these detection models 
the initial training of our model solely consisted of fruit 360 
to home refrigerator data is a novel and viable approach. We 
pictures. As a result, the model's performance was suboptimal 
encountered  challenges  in  adapting  the  model  to  the 
when it came to predicting fruits from real-time refrigerator 
complexities of real-time home refrigerator groceries storage, 
images, primarily due to the presence of multiple grocery 
which  differs  significantly  from  retail  shelving  data.  To 
items stacked together within the refrigerator environment. 
overcome  these  challenges,  we  enhanced  the  model's 
 
performance  by  incorporating  additional  cameras  and 
We leveraged the power of the YOLO system to develop a 
collecting more data for accurate predictions, regardless of 
custom-trained  machine-learning  solution  capable  of 
the  environment's  complexity.  shelves  with  storage  boxes 
proficiently performing object localization and multi-object 
exhibit  a  relatively  lower  level  of  intricacy  compared  to 
detection tasks. In addition to utilizing the Fruits 360 dataset 
shelves with unorganized items. Consequently, the shelves 
and  retail  groceries  datasets,  we  also  incorporated openly 
equipped  with  storage  boxes  demonstrated  better 
available  refrigerator  groceries  storage  pictures  data. 
performance metrics when compared to the data obtained 
Furthermore, we created additional data within the scope of 
from unorganized shelves. 
this  project  to  further  enhance  the  customization  of  the 
YOLO model.  VI.MODEL METRICS  
 
The following 3 parameters are commonly used for object 
As discussed in the datasets section, the YOLO model was 
detection tasks: · GioU is the Generalized Intersection over 
trained using a diverse range of data sources. These sources 
Union which tells how close to the ground truth our bounding 
included retail groceries data, a fruit dataset, open-source data 

box is. Objectness shows the probability that an object exists  the training dataset. As we used a combination of different 
in an image. Here it is used as a loss function. mAP is the  datasets for our training purpose, we utilized the concept of 
mean Average Precision telling how correct are our bounding  train-dev to ensure there is no data mismatch problem. In 
box predictions on  average. It  is  area  under  the  curve  of  addition,  our  metrics  are  calculated  using  real-time  data. 
precision-recall curve. It is seen that Generalized Intersection  Overall performance of the model in the case of “moisturized 
over Union (GIoU) loss and objectness loss decrease both for  food or containers”   was comparatively less.  
training  and  validation.  Mean  Average  Precision  (mAP) 
however is at 0.7 for bounding box IoU threshold of 0.5.     
Recall stands at 0.8 as shown below. 
 
   
 
Fig. 8.  Moisture or condensation inside food containers  
In  our  experiment,  we  understood  that,  more  than  the 
Fig. 6.  Model Metrics 
individual fruits dataset and groceries data set, refrigerator 
Predictions:  storage data has boosted model performance. Refrigerator 
data alone showed approximately similar results as the total 
 
dataset.  
        
VII.CONCLUSION & IMPACT OF THE MODEL  
 our system serves as an intelligent grocery tracking system, 
functioning as a personal assistant to assist residents in their 
daily food selection process, thereby enhancing their overall 
quality  of  life.  This  proves  particularly  beneficial  for 
individuals with busy schedules who prioritize their health 
and prefer home-cooked meals. Moreover, our system offers 
substantial  utility  across  various  customer  categories, 
catering to a diverse range of needs and preferences 
 
FUTURE SCOPE 
We found this field is very vast and there is high scope for 
improvement and research. Below are some ideas.  
1)  Integrate  the  supply  chain  groceries  prediction 
system[9]  to  achieve  more  accurate  predictions  of 
Fig. 7.  Model Predictions 
grocery  quantities  and  improve  the  overall  system 
Based on the detected groceries and supply chain user needed  efficiency.  
groceries list, the model decides whether to create an order or  2)  Integrate the system with AI based food suggestions 
not.  
system[8] so that based on users’ interests in that week, 
the system can automatically order groceries needed. 
After  using  the  application  for  a  period,  we  observed  a 
decline in performance. This decline can be attributed to the  3)  Create an advanced system capable of comprehending 
prolonged  storage  of  groceries  in  boxes,  resulting  in  the  complex  and  cluttered  groceries  storage  closets  by 
formation of a layer of water around the vegetables and inside  utilizing a vast array of high-resolution cameras. 
the boxes as shown in fig 9. Consequently, the images of the  4)  Create  an  advanced  vision-based  system  aimed  at 
groceries became blurry, causing confusion for the system. 
assessing  and  verifying  the  quality  and  freshness  of 
The  system  had  been  trained  on  higher-quality  images, 
grocery products. 
leading to a disparity between the trained picture quality and 
5)  By  employing  motion  detection  techniques,  we  can 
the real-time blurred picture data. Overall the performance 
develop an additional system that tracks users' actions 
was created by approximately the percentage of the moisture 
and monitors the movement of groceries entering and 
groceries. To address this issue, we took proactive measures 
leaving the closet. The data generated by this system 
by labeling new instances of "moisture" or "condensation 
can  serve  as  valuable  validation  for  the  predictions 
inside food container" groceries and incorporating them into 

made by the main model. Furthermore, this feature can  [16]  Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi, You 
Only  Look  Once:  Unified,  Real-Time  Object  Detection, 
be integrated into an ensemble model, combining it with 
https://arxiv.org/abs/1506.02640 
existing features to enhance overall performance and 
[17]  SHIVAM BANSAL, CNN Architectures: VGG, ResNet, Inception + 
accuracy.  TL,  https://www.kaggle.com/code/shivamb/cnn-architectures-vgg-
resnet-inception-tl/notebook 
ACKNOWLEDGMENT  
[18]  Joseph  Nelson,  Retail  Store  Item  Detection  using  YOLOv5, 
https://blog.roboflow.com/retail-store-item-detection-using-yolov5/ 
I would like to acknowledge the support of my mentors who 
[19]  Eran  Goldman, Roei  Herzig, Aviv  Eisenschtat, Oria  Ratzon, Itsik 
guided me throughout this project research. 
Levi, Jacob Goldberger, Tal Hassner , Precise Detection in Densely 
Packed Scenes, arXiv:1904.00853 
REFERENCES 
[20]  Eran  Goldman*  , Roei  Herzig* ,  Aviv  Eisenschtat*, Jacob 
  Goldberger, Tal  Hassner,  Github, 
[1]  Loveleen kaur1, Shreya Shah2, Muskan Gupta3, Rashmi Bhadoriya4,  https://github.com/eg4000/SKU110K_CVPR19  
Smart  Grocery  Monitoring  System  using  Smart  Sensors  and  IoT  [21]  Jaume  Ribas  Fernández 
Website: www.ijrdet.com (ISSN 2347-6435(Online) Volume 11, Issue  Bruno Siciliano (DIETI, Università degli Studi di Napoli Federico II) 
05,  May  2022)  ,  Riccardo Caccavale (DIETI, Università degli Studi di Napoli Federico 
https://www.ijrdet.com/files/Volume11Issue5/IJRDET_0522_01.pdf  II), Recognition of supermarket products using Computer Vision.  
[2]  Prof R. V. Babar, Chaitanya Bapat, M. S. Gaikwad, Grocery Inventry  [22]  Bikash Santra, Dipti Prasad Mukherjee, A comprehensive survey on 
Automation Using Internet of Things and BLE Network, International  computer  vision  based  approaches  for  automatic  identification  of 
Journal  of  Innovative  Research  in  Science,  Engineering  and  products  in  retail  store,  Volume  86, June  2019,  Pages  45-63, 
Technology  https://www.sciencedirect.com/science/article/abs/pii/S026288561930
(An  ISO  3297:  2007  Certified  Organization)  0277 
Vol.  5,  Issue  7,  July 
[23]  Swagat  Kumar†‡,  Anima  Majumder∗,  Samrat  Dutta∗,  Sharath 
2016 ,http://www.ijirset.com/upload/2016/july/211_Chaitanya.pdf 
Jotawar†,  Ashish  Kumar∗,  Manish  Soni†,  Venkat  Raju†,  Olyvia 
[3]  K. -s. Hong, H. J. Kim and C. Lee, "Automated Grocery Ordering  Kundu† , Ehtesham Hassan†, Laxmidhar Behera∗, K. S. Venkatesh∗ 
Systems  for  Smart  Home," Future Generation Communication and  and Rajesh Sinha, Design and Development of an automated Robotic 
Networking (FGCN 2007), Jeju, Korea (South), 2007, pp. 87-92, doi:  Pick  &  Stow  System  for  an  e-Commerce  Warehouse, 
10.1109/FGCN.2007.74,  https://arxiv.org/pdf/1703.02340.pdf 
https://ieeexplore.ieee.org/document/4426209 
[24]  Michele Merler , Carolina Galleguillos, Serge Belongie, Recognizing 
[4]  Parv Gupta, Use Computer Vision for Product Detection on a Grocery  Groceries  in  situ  Using  in  vitro  Training  Data,  
Shelf,  https://levelup.gitconnected.com/product-detection-from- https://www.michelemerler.com/papers/grozi_cvprw07.pdf 
grocery-shelf-9db031e0ddc1 
[25]  E  Gothai,  Surbhi  Bhatia,  Design  Features  of  Grocery  Product 
[5]  LG’s ThinQ provides some promised features, but not others, usatoday,   Recognition Using Deep Learning, Intelligent Automation and Soft 
https://reviewed.usatoday.com/refrigerators/features/smart- Computing  34(2):1231-1246, 
refrigerator-organize-groceries  https://www.researchgate.net/publication/360352975_Design_Feature
[6]  Prabu Selvam, A Deep Learning Framework for Grocery Product  s_of_Grocery_Product_Recognition_Using_Deep_Learning 
[7]  Detection  and  Recognition,  [26]  Joseph  Nelson,  Retail  Store  Item  Detection  using  YOLOv5, 
https://www.researchsquare.com/article/rs-1431986/v1  https://blog.roboflow.com/retail-store-item-detection-using-yolov5/ 
[8]  MEREDDY DIVYA. (2023). NLP-BASED FOOD SUGGESTIONS  [27]  shayanalibhatti,  Retail  Store  Item  Detection  using  YOLOv5, 
SYSTEM  –  SMART  HOMES.  https://github.com/shayanalibhatti/Retail-Store-Item-Detection-using-
https://doi.org/10.5281/zenodo.7619036  YOLOv5?ref=blog.roboflow.com 
[9]  MEREDDY  DIVYA.  (2023).  Groceries  Ordering  System  -  Smart  [28]  Li  Shen,  Detect  Dense  Products  on  Grocery  Shelves  with  Deep 
Homes Supply Chain. https://doi.org/10.5281/zenodo.7998210  Learning  Techniques, 
https://hammer.purdue.edu/articles/thesis/Detect_Dense_Products_on
[10]  Mereddy Divya. (2023). Groceries Tracking System - Smart Homes 
_Grocery_Shelves_with_Deep_Learning_Techniques/12158973 
[Data set]. Zenodo. https://doi.org/10.5281/zenodo.7996592 
[29]  Mihai  Oltean, Fruits  360, 
[11]  Goldman  et  al,  SKU110K  dataset,  http://trax-
https://www.kaggle.com/datasets/moltean/fruits?datasetId=5857&sort
geometry.s3.amazonaws.com/cvpr_challenge/SKU110K_fixed.tar.gz  
By=relevance&sort=recent-comments 
[12]  gulvarol,  Grocery  Dataset, 
[30]  Arnab Bhakta, Fruits and Vegetables Classification with Fruits 360 
https://github.com/gulvarol/grocerydataset#shelfimages 
dataset  using  Deep  Learning, 
[13]  Neurolabs, CASE STUDY: How A European Supermarket Chain Is 
https://medium.com/@arnabbhakta956/fruits-and-vegetables-
Solving  On-Shelf  Availability  With  Synthetic  Computer  Vision, 
classification-with-fruits-360-dataset-using-deep-learning-
https://neurolabs.medium.com/how-a-european-supermarket-chain-is-
36610f9c2122 
solving-on-shelf-availability-with-synthetic-computer-vision-
[31]  Bikash Santra, Dipti Prasad Mukherjee, A comprehensive survey on 
587d0c15c51c 
computer  vision  based  approaches  for  automatic  identification  of 
[14]  Roboflow, https://app.roboflow.com/  
products in retail store,Image and Vision Computing, Volume 86, June 
[15]  Kaiming He Xiangyu Zhang Shaoqing Ren, Microsoft Research, Deep  2019,  Pages  45- 
Residual  Learning  for  Image  63,https://www.sciencedirect.com/science/article/abs/pii/S026288561
Recognition,https://arxiv.org/pdf/1512.03385.pdf  9300277
 