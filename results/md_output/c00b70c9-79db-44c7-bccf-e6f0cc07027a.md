Constrained Quadratic Risk Minimization via Forward and
Backward Stochastic Differential Equations
Yusong Li∗ and Harry Zheng†
7102 yaM 22  ]MP.nif-q[  2v38540.2151:viXra
Abstract
In this paper we study a continuous-time stochastic linear quadratic control problem
arising from mathematical finance. We model the asset dynamics with random market
coefficients and portfolio strategies with convex constraints. Following the convex duality
approach, we show that the necessary and sufficient optimality conditions for both the
primal and dual problems can be written in terms of processes satisfying a system of
FBSDEs together with other conditions. We characterise explicitly the optimal wealth
and portfolio processes as functions of adjoint processes from the dual FBSDEs in a
dynamic fashion and vice versa. We apply the results to solve quadratic risk minimization
problems with cone-constraints and derive the explicit representations of solutions to the
extended stochastic Riccati equations for such problems.
Keywords: convex duality, primal and dual FBSDEs, stochastic linear quadratic control,
random coefficients, control constraints
AMS MSC2010: 91G80, 93E20, 49N05, 49N15
1 Introduction
In this paper we study a stochastic control problem arising from mathematical finance. The
goal is to minimize a convex cost function that is quadratic in both the wealth process and
portfolio strategy in a continuous time complete market with random market parameters
and portfolio constraints. Problems of this kind arise naturally in financial applications.
We assume that the portfolio must take value in a given closed convex set which is general
enough to model short selling, borrowing, and other trading restrictions, see [10].
There are vast literatures on stochastic linear quadratic (SLQ) optimal control and its
applications on mean variance portfolio selection problems, see [19, 21] and references therein.
In the absence of portfolio constraints, using the stochastic maximum principle, one can solve
the SLQ problem by deriving the optimal control as a linear feedback control of the state
and proving the existence and uniqueness of a solution to the resulting stochastic Riccati
equation (SRE). When there are no control constraints, the feedback control constructed
from the solution of the SRE is automatically admissible, see [22] for an example of this
method to problems with random coefficients but no portfolio constraints. When there are
control constraints, the optimal control is no longer a simple linear feedback control of the
state and the SRE method becomes much more difficult and subtle. [8] shows the solvability
of an extended SRE for constrained SLQ problems with random coefficients.
For convex SLQ problems, it is also natural to use the convex duality method that has
been extensively applied to solve utility maximization problems in mathematical finance,
∗Department of Mathematics, Imperial College, London SW7 2BZ, UK. Email: y.li11@imperial.ac.uk
†Department of Mathematics, Imperial College, London SW7 2BZ, UK. Email: h.zheng@imperial.ac.uk
1

see [11, 12] and reference therein. When there are no control constraints and the filtration
is generated by driving Brownian motions, one may first convert the original dynamic op-
timization problem into an equivalent static one, then formulate and solve the static dual
problem, and use the dual relation and the martingale property to find the optimal state
process for the original problem, finally use the martingale representation theorem to find a
replicating portfolio which is the optimal control process. When there are control constraints,
the duality method becomes much more complicated. [10] introduces and solves a family of
auxiliary unconstrained problems and shows one of them solves the original constrained prob-
lem. [14] applies the convex duality approach, inspired by [2, 18], to solve a mean-variance
problem with both random coefficients and portfolio constraints and shows the existence of
an optimal solution to the dual problem and constructs the optimal wealth process with the
optimal dual solution and the optimal portfolio process with the martingale representation
theorem. [4] provides a comprehensive treatment on mean-variance hedging under convex
trading constraints in a general semi-martingale setting. It establishes the closedness of
the set of all replicable terminal wealth under trading constraints in some square integrable
sense and subsequently the existence of a solution to mean-variance hedging problems, and
extends results linking the primal and dual problems obtained previously by other authors,
see detailed discussions in [4, Section 5.3].
[15] extends the results of [12] to a dynamic setting and proves a close relation between
optimal solutions and adjoint processes obtained from forward backward stochastic differ-
ential equations (FBSDEs). Specifically, it is shown that the optimal primal wealth and
portfolio processes can be expressed as functions of the optimal adjoint processes of the dual
problem and vice versa. This demystifies the opaque relation of the optimal solutions of
the primal and dual problems in utility maximization, i.e., given the solution of the dual
problem, the optimal control of the primal problem can only be derived from the martingale
representation theorem. There are no control constraints in [15] but the asset price process
is a general semi-martingale process with some technical conditions.
Inspired by the work of [15], we use the convex duality method to solve the quadratic
risk minimization problem with both random coefficients and control constraints. To get a
correct formulation of the dual problem, we follow the approach of [14] by first converting the
original problem into a static problem in an abstract space, then applying convex analysis to
derive its dual problem, and finally getting a specific dual stochastic control problem. It turns
out there are three controls in the dual problem, one corresponds to the control constraint
set, one to the running cost function, and one to the no-duality-gap relation. Using FBSDEs,
we derive the necessary and sufficient conditions for both primal and dual problems, which
allows us to explicitly characterise the primal control as a function of the adjoint process
coming from the dual FBSDEs in a dynamic fashion and vice versa, similar to those in [15].
Moreover, we also find that the optimal primal wealth process coincides with the optimal
adjoint process of the dual problem and vice versa. To the best of our knowledge, this is the
first time the dynamic relations of primal and dual problems with control constraints have
been explicitly characterized in terms of solutions to their corresponding FBSDE systems.
After establishing the optimality conditions for both primal and dual problems, we solve
a quadratic risk minimization problem with cone-constraints. Instead of attacking the primal
problem directly, we start from the dual problem and then construct the optimal solution
to the primal problem from that of the dual problem. Moreover, we derive the explicit
representations of solutions to the extended SREs introduced in [8] in terms of the optimal
solutions from the dual problem. The simplicity in solving the dual problem is in good
contrast to the technical complexity in solving the extended SREs directly, as discussed in
[8]. In addition, we show that when the coefficients are deterministic, the closed form optimal
solution to the dual problem can be constructed.
2

The rest of the paper is organised as follows. In Section 2 we set up the model and
formulate the primal and dual problems following the approach in [14]. In Section 3 we
characterise the necessary and sufficient optimality conditions for both the primal and dual
problems and establish their connection in a dynamic fashion through FBSDEs. In Section 4
we discuss quadratic risk minimization problems with cone constraints and demonstrate how
to construct explicitly the solutions of the extended SREs from those of the dual FBSDEs.
In Section 5 we prove the main results. Section 6 concludes.
2 Market Model and Primal and Dual Problems
RN
Through out the paper, we denote by T > 0 a fixed terminal time, {W(t),t ∈ [0,T]} a -
valued standard Brownian motion with scalar entries W (t), m = 1,··· ,N, on a complete
m
probability space (Ω,F,P ), {F } the P -augmentation of the filtration FW = σ(W(s),0 ≤ s ≤
t t
P(0,T;RN RN
t) generated by W, ) the set of all -valued progressively measurable processes
on [0,T] × Ω, H2(0,T;RN ) the set of processes x in P(0,T;RN ) satisfying E[ T |x(t)|2dt] <
0
∞, and S2(0,T;RN ) the set of processes x in P(0,T;RN ) satisfying E[sup |x2|] < ∞.
0≤t≤T t
R
We write SDE for stochastic differential equation, BSDE for backward SDE, and FBSDE for
forward and backward SDE. We also follow the customary convention that ω is suppressed
in SDEs and integrals, except in places where an explicit ω is needed.
Consider a market consisting of a bank account with price {S (t)} given by
0
dS (t) = r(t)S (t)dt, 0 ≤ t ≤ T, S (0) = 1, (2.1)
0 0 0
and N stocks with prices {S (t)}, n = 1,··· ,N, given by
n
N
dS (t) = S (t) b (t)dt + σ (t)dW (t) , 0 ≤ t ≤ T, S (0) > 0. (2.2)
n n n nm m n
" #
m=1
X
P(0,T;R P(0,T;RN
We assume that r ∈ ) (scalar interest rate), b ∈ ) (vector of appreciation
P(0,T;RN×N
rates), and σ ∈ ) (volatility matrix) are uniformly bounded. We also assume
that there exists a positive constant k such that
z′σ(t)σ′ (t)z ≥ k|z|2
for all (z,ω,t) ∈ RN × Ω × [0,T], where z′ is the transpose of z. The strong non-degeneracy
condition above ensures that matrices σ(t),σ′(t) are invertible and uniformly bounded.
Consider a small investor with initial wealth x > 0 and a self-financing strategy. Define
0
the set of admissible portfolio strategies by
H2(0,T;RN
A := π ∈ ) : π(t) ∈ K for t ∈ [0,T] a.e. ,
RN clo(cid:8) portfol(cid:9)
where K ⊆ is a sed convex set containing 0 and π is a io process with each
entry π (t) defined as the amount invested in the stock n for n = 1,... ,N. Given any π ∈ A,
n
Xπ
the investor’s total wealth satisfies the SDE
dXπ (t) = [r(t)Xπ (t) + π′(t)σ(t)θ(t)]dt + π′(t)σ(t)dW(t), 0 ≤ t ≤ T,
(2.3)
Xπ (0) = x ,
0
(cid:26)
where θ(t) := σ−1(t)[b(t) − r(t)1] is the market price of risk at time t and is uniformly
RN
bounded and 1 ∈ has all unit entries. A pair (X,π) is admissible if π ∈ A and X is a
strong solution to the SDE (2.3) with control process π.
3

R
Define a functional J : A → by
T
π π
J(π) := E f(t,X (t),π(t))dt + g(X (T)) ,
0
(cid:20)Z (cid:21)
R RN R R R
where f : Ω × [0,T] × × → and g : Ω × → are defined by
1
f(ω,t,x,π) := Q(t)x2 + 2S′(t)xπ + π′R(t)π ,
2
(2.4)

1 (cid:2) (cid:3)
 g(ω,x) := ax2 + 2cx .

2
 (cid:2) (cid:3)
We assume that ran dom variables a,c ∈ L∞ (R ) satisfy
FT
0 < inf a(ω) ≤ sup a(ω) < ∞
ω∈Ω
ω∈Ω
P(0,T;R P(0,T;RN P(0,T;RN×N
and processes Q ∈ ),S ∈ ),R ∈ ) are uniformly bounded,
R(t) is a symmetric matrix, and the matrix
Q(t) S′(t)
S(t) R(t)
(cid:18) (cid:19)
is non-negative definite for all (ω,t) ∈ Ω × [0,T]. Under these assumptions we know J is a
convex functional of π.
We consider the following optimization problem:
Minimize J(π) subject to (X,π) admissible. (2.5)
An admissible control πˆ is optimal if J(πˆ) ≤ J(π) for all π ∈ A.
Following the approach introduced in [14], we now set up the dual problem. Denote by
B :=R × H2 (0,T;R ) × H2 (0,T;RN ).
B
We write X ∈ if and only if
t t
X(t) = x + X˙ (τ)dτ + Λ′ (τ)dW(τ), 0 ≤ t ≤ T,
0 X
0 0
Z Z
˙ B
for some (x ,X,Λ ) ∈ . We now reformulate (2.5) as a primal optimization problem over
0 X
B ˙ B
the whole set . For each X ≡ (x ,X,Λ ) ∈ , define
0 X
U(X) := {π ∈ A such that X˙ (t) = r(t)X(t) + π′ (t)σ(t)θ(t)
and Λ (t) = σ′ (t)π(t) for ∀t ∈ [0,T], P − a.e.}.
X
The set U(X) contains all admissible controls π ∈ A that make X an admissible wealth
∅ ˙ P
process. Note that U(X) 6= if and only if (X(t),Λ (t)) ∈ S(t,X(t)) for ( ⊗ Leb)-a.e.
X
(ω,t) ∈ Ω × [0,T], where S is a set valued function defined by
S(ω,t,x) := {(v,ξ) : v = r(t)x + ξ′θ(t) and σ′ −1 (t)ξ ∈ K}.
R R RN →(cid:2) [0,(cid:3)
Define the penalty function L : Ω × [0,T] × × × ∞] by
L(ω,t,x,v,ξ) = f ω,t,x,[σ′ ]−1 (t)ξ + Ψ (v,ξ)
S(ω,t,x)
(cid:0) (cid:1)
4

R
and the penalty function l : → [0,∞] by
0
l (x) = Ψ (x),
0 {x0}
where Ψ (u) is a penalty function which equals 0 if u is in set U and +∞ otherwise.
U
B
For X ∈ , define the cost functional as
T
˙
Φ(X) := l (x ) + E [g(X(T))] + E L(t,X(t),X(t),Λ (t))dt .
0 0 X
0
(cid:20)Z (cid:21)
∅
Note that Φ(X) = ∞ if X(0) 6= x or U(X) = . Problem (2.5) is equivalent to
0
B
Minimize Φ(X) subject to X ∈ .
B
We now establish the dual problem over the set . Define the following convex conjugate
functions
m (y) := sup{xy − l (x)},
0 0
x∈R
m (ω,y) := sup{−xy − g(ω,x)},
T
x∈R
M(ω,t,y,s,γ) := sup {xs + vy + ξ′γ − L(ω,t,x,v,ξ)},
x,v∈R,ξ∈RN
R R RN (y,Y˙ B
for all (ω,t,y,s,γ) ∈ Ω × [0,T] × × × . For each Y ≡ ,Λ ) ∈ , define
Y
T
˙
Ψ(Y ) := m (y) + E [m (Y (T))] + E M(t,Y (t),Y (t),Λ (t))dt .
0 T Y
0
(cid:20)Z (cid:21)
Then the dual problem is given by
B
Minimize Ψ(Y ) subject to Y ∈ .
We can write the dual problem equivalently as a stochastic control problem. Some simple
calculus gives
m (y) = x y,
0 0
(y + c)2
m (ω,y) = ,
T
2a
M(ω,t,y,s,γ) = φ(t,s + r(t)y,σ(t)[θ(t)y + γ]), (2.6)
˜
where φ is the conjugate function of f(ω,t,x,π) = f(ω,t,x,π) + Ψ (π), namely,
K
φ(ω,t,α,β) := sup {xα + π′β − f(ω,t,x,π)}.
x∈R,π∈K
The dual control problem is therefore given by
T
˜
Minimize Ψ(y,α,β) := m (y) + E [m (Y (T))] + E φ(t,α(t),β(t))dt , (2.7)
0 T
0
(cid:20)Z (cid:21)
where Y satisfies
′
dY (t) = [α(t) − r(t)Y (t)]dt + σ−1(t)β(t) − θ(t)Y (t) dW(t)
(2.8)
( Y (0) = y. (cid:2) (cid:3)
˙
Here we have used the relation (2.6) to get α(t) = Y (t)+r(t)Y (t) and β(t) = σ(t)(θ(t)Y (t)+
Λ (t)), which shows Y˙ (t) = α(t) − r(t)Y (t) and Λ (t) = σ−1(t)β(t) − θ(t)Y (t), for the dual
Y Y
B
process Y . The dual control process for Y is (y,α,β) ∈ . From [13, Corollary 2.5.10], we
have Y (y,α,β) ∈ S2(0,T;R ). Note that the control constraint is implicit for the dual problem.
For example, if Q = 0,S = 0,R = 0, then α must be zero and may be simply dropped in
(2.7) and (2.8).
5

Remark 1. (Alternative way of deriving the dual problem) We have followed [14] to derive
the dual problem (2.7) and (2.8) by first converting the primal dynamic problem into a static
problem, then applying convex analysis to get the static dual problem, and finally recovering
the dual dynamic problem. One may derive the dual problem (2.7) and (2.8) directly using
a standard method in utility maximization in mathematical finance. Specifically, we may
assume the dual process Y is driven by a SDE
dY (t) = α (t)dt + β (t)dW(t)
1 1
with initial condition Y (0) = y, where α and β are two stochastic processes to be deter-
1 1
mined. Ito’s lemma gives
d(Xπ (t)Y (t)) = (Xπ (t)α(t) + π′ (t)β(t))dt + local martingale,
where α(t) = α (t) + r(t)Y (t) and β(t) = σ(t)(β (t) + θ(t)Y (t)). Since α (t) = α(t) −
1 1 1
r(t)Y (t) and β (t) = σ−1(t)β(t) − θ(t)Y (t), we have Y satisfies SDE (2.8). The process
1
Xπ (t)Y (t) − t (Xπ (s)α(s) + π′(s)β(s))ds is a local martingale and a super-martingale if we
0
assume further that it is bounded below by an integrable process, in particular, we have the
R
relation
T
E Xπ (T)Y (T) − (Xπ (s)α(s) + π′ (s)β(s))ds ≤ Xπ (0)Y (0) = x y. (2.9)
0
0
(cid:20) Z (cid:21)
The constrained minimization problem (2.5) can be written equivalently as
T
π π
maxE (−f(t,X (t),π(t)) − Ψ (π(t)))dt − g(X (T)) .
K
π
0
(cid:20)Z (cid:21)
The dual functions of −f(t,·,·) − Ψ (·) and −g(·) are given by
K
φ(t,α,β) = sup{−f(t,x,π) − Ψ (π) + xα + π′β} and m (y) = sup(−g(x) − xy).
K T
x,π x
Combining the dual relations above and (2.9), we have
T
π π
maxE (−f(t,X (t),π(t)) − Ψ (π(t)))dt − g(X (T))
K
π
0
(cid:20)Z (cid:21)
T
≤ min x y + E φ(t,α(t),β(t))dt + m (Y (T)) ,
0 T
y,α,β
0
(cid:26) (cid:20)Z (cid:21)(cid:27)
which gives the dual problem (2.7).
Remark 2. (Existence of optimal solutions) Following a similar argument as in [14, Propo-
˜ B
sition 5.4], we can show that Ψ defined in (2.7) is convex on due to convexity of m and
T
˜ B
φ and linearity of state equation (2.8). Since Ψ(y,α,β) > x y > −∞ for all (y,α,β) ∈
0
2
˜ c ˜
and Ψ(0,0,0) = E < ∞, we have Ψ is proper. Furthermore, by the non-negativity
2a
˜
and semi-continuityhof iφ and Fatou’s lemma, we conclude that Ψ is lower semi-continuous
B ˜ ˜
on . Finally, using Itˆo’s isometry, we can show that Ψ is coercive (i.e., Ψ(y,α,β) →
∞ as k(y,α,β)k → ∞). Hence, the existence of a solution to the dual problem is guaranteed
ˆ B
from [7, Chapter 2, Proposition 1.2], that is, there exists some (yˆ,αˆ,β) ∈ such that
˜ ˜ ˆ R
inf Ψ(y,α,β) = Ψ(yˆ,αˆ,β) ∈ .
(y,α,β)∈B
ˆ
Given the dual optimal solution (yˆ,αˆ,β), we may apply Theorem 9 to construct an optimal
control πˆ for problem (2.5), which proves the existence of a solution to the primal problem.
It is more difficult, but accomplishable, to prove directly the existence of a solution to the
primal problem as one needs to show the closedness of the set of all replicable terminal wealth
under pointwise control constraints, see [4] (also [5]) for detailed discussions.
6

3 Main Results
In this section, we derive the necessary and sufficient optimality conditions for primal and
dual problems and show the connection between the optimal solutions through their corre-
sponding FBSDEs. To highlight the main results and streamline the discussion, we leave the
proofs of all the theorems in Section 5.
Given any admissible control π ∈ A and solution Xπ to the SDE (2.3), the associated
S2(0,T;R H2(0,t;RN
adjoint equation in unknown processes p ∈ ) and q ∈ ) is the following
1 1
linear BSDE
dp (t) = [−r(t)p (t) + Q(t)X(t) + S′(t)π(t)]dt + q′ (t)dW(t)
1 1 1
(3.1)
( p (T) = −aXπ (T) − c.
1
From [16, Theorem 6.2.1] we know that there exists a unique solution (p ,q ) to the BSDE
1 1
(3.1). We now state the necessary and sufficient conditions for the primal problem.
Theorem 3. (Primal problem and associated FBSDE) Let πˆ ∈ A. Then πˆ is optimal for
the primal problem if and only if the solution (Xπˆ,pˆ ,qˆ ) of FBSDE
1 1
dXπˆ(t) = r(t)Xπˆ(t) + πˆ′(t)σ(t)θ(t) dt + πˆ′(t)σ(t)dW(t)
Xπˆ(0) = x
0
 (cid:2) (cid:3) (3.2)
dpˆ (t) = −r(t)pˆ (t) + Q(t)Xπˆ(t) + S′(t)πˆ(t) dt + qˆ′ (t)dW(t)
  1 1 1
 pˆ (T) = −aXπˆ(T) − c
1
(cid:2) (cid:3)


satisfies the condition
πˆ′ − π′ pˆ (t)σ(t)θ(t) + σ(t)qˆ (t) + S(t)Xπˆ (t) + R(t)πˆ(t) ≥ 0 (3.3)
1 1
h i
(cid:2) (cid:3)
P
for ( ⊗ Leb)-a.e. (ω,t) ∈ Ω × [0,T] and π ∈ K.
Remark 4. If one knows the optimal control πˆ, it is easy to find the optimal wealth process
Xπˆ and the adjoint process (pˆ ,qˆ ) as (3.2) is a decoupled linear FBSDE given πˆ. It is much
1 1
more difficult, but most interesting, to find the optimal control πˆ using (3.2) and (3.3), which
is related to the solvability of a fully coupled constrained linear FBSDE. From Remark 2, we
know there exists a solution (Xπˆ,pˆ ,qˆ ) to the constrained FBSDE (3.2) and (3.3). It is
1 1
RN
a challenge on how one may actually find the solution. If K = , then condition (3.3)
becomes
S(t)Xπˆ
pˆ (t)σ(t)θ(t) + σ(t)qˆ (t) + (t) + R(t)πˆ(t) = 0.
1 1
If we further assume R(t) is positive definite and R(t)−1 is uniformly bounded, then we can
substitute the optimal control πˆ(t) into the FBSDE (3.2) to get a fully-coupled linear FBSDE
with random coefficients, see [20] for discussions on the solvability of linear FBSDEs.
Given any admissible control (y,α,β) ∈ B and solution Y (y,α,β) to the SDE (2.8), the
S2(0,T;R H2(0,t;RN
associated adjoint equation in unknown processes p ∈ ) and q ∈ ) is
2 2
the following linear BSDE
dp (t) = [r(t)p (t) + q′ (t)θ(t)]dt + q′ (t)dW(t)
2 2 2 2
Y (y,α,β)(T) + c (3.4)
 p (T) = − .
2
 a
From [16, Theorem 6.2.1], we know that there exists a unique solution (p ,q ) to the BSDE
2 2
(3.4). To derive the necessary condition, we need to impose the following assumption on φ
ˆ
at the optimal dual control process (αˆ,β).
7

ˆ
Assumption 5. Let (αˆ,β) be given and α,β be any admissible control. Then there exists a
R T
Z ∈ P(0,T; ) satisfying E[ |Z(t)|dt] < ∞ and
0
R
ˆ ˆ
φ(t,αˆ(t) + εα(t),β(t) + εβ(t)) − φ(t,αˆ(t),β(t))
Z(t) ≥ (3.5)
ε
P
for ( ⊗ Leb)-a.e. (ω,t) ∈ Ω × [0,T] and ε ∈ (0,1].
Remark 6. Here are a few comments on Assumption 5.
1. Condition (3.5) is a technical condition that ensures one can apply the monotone con-
vergence theorem and pass the limit under the expectation and integral as ε ↓ 0, which
is used in proving the second and third relations in (3.7), see the proof of Theorem 7
in Section 5. A similar assumption is used in [3, Assumption 1.2] on the data of the
primal problem.
RN
2. If K = , S(t) = 0 and Q(t),R(t) are positive definite and their inverses are uni-
formly bounded, then φ(t,α,β) = 1Q(t)−1α2 + 1β′R(t)−1β. Condition (3.5) holds if Z
2 2
is chosen to be
1 1
Z(t) := Q(t)−1αˆ(t)α(t) + βˆ′ (t)R(t)−1β(t) + Q(t)−1α(t)2 + β′ (t)R(t)−1β(t).
2 2
3. If Q(t) = 0,S(t) = 0,R(t) = 0, then α(t) = 0 for the dual problem. We may drop α in
the expression of φ which becomes a support function of K, i.e., φ is given by φ(t,β) =
δ(β) := sup π′β. If we further assume that K is a bounded set, then condition
π∈K
(3.5) holds if Z is chosen to be Z(t) = δ(β(t)). However, if K is unbounded, then
Assumption 5 may not hold and we cannot use the monotone convergence theorem to
prove (3.7). Other methods may have to be used, see Remark 13 for further discussions.
We now state the necessary and sufficient conditions for the dual problem.
ˆ B
Theorem 7. (Dual problem and associated FBSDE) Let (yˆ,αˆ,β) ∈ satisfy Assumption 5.
Then (yˆ,αˆ,βˆ ) is optimal for the dual problem if and only if the solution (Y (yˆ,αˆ,βˆ ),pˆ ,qˆ ) of
2 2
FBSDE
′
dY (yˆ,αˆ,βˆ )(t) = αˆ(t) − r(t)Y (yˆ,αˆ,βˆ )(t) dt + σ−1(t)βˆ (t) − θ(t)Y (yˆ,αˆ,βˆ )(t) dW(t)
 h i h i
(yˆ,αˆ,βˆ
Y )(0) = yˆ



 (3.6)

 dpˆ (t) = [r(t)pˆ (t) + qˆ′ (t)θ(t)]dt + qˆ′ (t)dW(t)
  2 2 2 2

(yˆ,αˆ,βˆ
Y )(T) + c
 pˆ (T) = −
 2
 a





satisfies the conditions
pˆ (0) = x ,
2 0
[σ′]−1
 (t)qˆ (t) ∈ K,
2 (3.7)



 (t),[σ′]−1 ∂φ(αˆ(t),βˆ
pˆ (t)qˆ (t) ∈ (t)),
2 2
 (cid:16) (cid:17)

P 
for ( ⊗ Leb)-a.e. (ω,t) ∈ Ω × [0,T].
8

Remark 8. Similar discussions as in Remark 4 apply here. If one knows the optimal control
ˆ
(yˆ,αˆ,β), it is easy to find the optimal dual process Y and the adjoint process (pˆ ,qˆ ) as (3.6)
2 2
ˆ
is a decoupled linear FBSDE given (yˆ,αˆ,β). It is much more difficult, but most interesting, to
(yˆ,αˆ,βˆ RN
find the optimal control ) using (3.6) and (3.7). If K = , S(t) = 0 and Q(t),R(t)
are positive definite, then from Remark 6, φ is a quadratic function of α and β and we can
ˆ
write optimal controls αˆ and β in terms of adjoint processes pˆ and qˆ . The FBSDE (3.6)
2 2
becomes a fully coupled linear FBSDE with an additional condition pˆ (0) = x , which is used
2 0
to determine the constant control yˆ.
We can now state the dynamic relations of the optimal portfolio and wealth processes of
the primal problem and the adjoint processes of the dual problem and vice versa.
ˆ
Theorem 9. (From dual problem to primal problem) Suppose that (yˆ,αˆ,β) is optimal for
(yˆ,αˆ,βˆ
the dual problem. Let Y ),pˆ ,qˆ be the associated process that satisfies the FBSDE
2 2
(3.6) and condition (3.7(cid:16)). Define (cid:17)
πˆ(t) := σ′ −1 (t)qˆ (t), t ∈ [0,T]. (3.8)
2
Then πˆ is the optimal control for th(cid:2)e p(cid:3)rimal problem with initial wealth x . The optimal
0
wealth process and associated adjoint processes are given by
Xπˆ(t) = pˆ (t),
2
(yˆ,αˆ,βˆ
pˆ (t) = Y )(t), (3.9)
 1
  qˆ (t) = σ−1(t)βˆ (t) − θ(t)Y (yˆ,αˆ,βˆ )(t) for ∀t ∈ [0,T].
1
Remark 10. The key benefit of Theorem 9 is that if one can solve the dual problem, then one

can get automatically the optimal control πˆ for the primal problem using (3.8). As discussed
in Remark 4, it is in general difficult to find the optimal control πˆ using (3.2) and (3.3)
directly. Section 4.2 provides an example to illustrate this point.
Theorem 11. (From primal problem to dual problem) Suppose that πˆ ∈ A is optimal for the
primal problem with initial wealth x . Let Xπˆ,pˆ ,qˆ be the associated process that satisfies
0 1 1
the FBSDE (3.2) and condition (3.3). Define
(cid:0) (cid:1)
yˆ = pˆ (0),
1
 αˆ(t) = Q(t)Xπˆ(t) + S′(t)πˆ(t), (3.10)


 ˆ
β(t) = σ(t)[qˆ (t) + θ(t)pˆ (t)].
1 1

ˆ 
Then (yˆ,αˆ,β) is the optimalcontrol for the dual problem. The optimal dual state process
and associated adjoint processes are given by
(yˆ,αˆ,βˆ
Y )(t) = pˆ (t),
1
 pˆ (t) = Xπˆ(t), (3.11)
2

  qˆ (t) = σ′(t)πˆ(t).
2

Remark 12. The main results (Theorems 3, 7, 9 and 11) can be extended to utility max-

imization problems with quadratic cost functions being replaced by utility functions. The
ideas are similar but proofs are much more complicated as utility functions are only defined
on the positive real line with unbounded non-Lipschitz derivatives, in contrast to quadratic
functions which are defined on the whole real line with linear derivatives. The authors have
a separate paper discussing the details of dynamic relations of the primal and dual problems
for general utility functions with control constraints via maximum principles and FBSDEs
and will publish the results elsewhere.
9

4 Quadratic Risk Minimization with Cone Constraints
In this section we consider the following quadratic risk minimization problem:
1
Minimize J(π(·)) = E aX(T)2 ,
2 (4.1)
 (cid:20) (cid:21)
  Subject to (X(·),π(·)) is admissible.

Assume K ⊂ RN is a closed convex cone. The dual problem is given by
Y (T)2 T
Minimize x y + E + E δ(β(t))dt (4.2)
0
2a
0
(cid:20) (cid:21) (cid:20)Z (cid:21)
R H2(0,T;RN
over (y,β) ∈ × ), where Y satisfies the SDE (2.8) with α(t) = 0 and δ(β) =
sup π′β, the support function of K. [14, Proposition 5.4] states that there exists an
π∈K
ˆ ˆ
optimal control (yˆ,β) to (4.2) with associated optimal state process Y .
Remark 13. Since K is unbounded, Assumption 5 may not hold. Using the subadditivity
and positive homogeneity of δ, we have (see (5.9))
T
E δ(β(t)) − qˆ′ (t)σ−1 (t)β(t) dt ≥ 0. (4.3)
2
0
(cid:20)Z (cid:21)
(cid:2) (cid:3)
[σ′]−1
Let B := {(ω,t) ∈ Ω × [0,T] : (t)qˆ (t) ∈ K}. By [10, Lemma 5.4.2], there exists
2
P(0,T;RN
ν ∈ ) such that |ν(t)| ≤ 1 and |δ(ν(t))| ≤ 1 and
σ′ −1 (t)qˆ (t) ∈ K ⇔ ν(t) = 0,
2
(cid:2)σ′ (cid:3)−1 (t)qˆ (t) 6∈ K ⇔ δ(ν(t)) − qˆ′ (t)σ−1 (t)ν(t) < 0
2 2
P (cid:2) (cid:3)
for ( ⊗ Leb)-a.e. (ω,t) ∈ Ω × [0,T]. The existence of ν ensures that the complement set
of B has measure zero on Ω × [0,T] (otherwise there is a contradiction to (4.3)). Hence we
[σ′]−1 (P
conclude (t)qˆ (t) ∈ K for ⊗ Leb)-a.e. The third relation in (3.7) can also be proved
2
directly.
4.1 Random coefficient case
We have the following result.
ˆ ˆ
Lemma 14. Let (yˆ,β) be the optimal control of the dual problem (4.2) and Y be the cor-
ˆ ˆ P
responding optimal state process. Then β(t) = 0 if Y (t) = 0 for ( ⊗ Leb)-a.e. (ω,t) ∈
Ω × [0,T].
Proof. Applying Ito’s formula to Yˆ (t)2, we get
′
dYˆ (t)2 = −2r(t)Yˆ (t)2 + σ−1 (t)βˆ (t) − θ(t)Yˆ (t) σ−1 (t)βˆ (t) − θ(t)Yˆ (t) dt
(cid:20) (cid:21)
(cid:16) (cid:17) (cid:16) (cid:17)
′
+ 2Yˆ (t) σ−1 (t)βˆ (t) − θ(t)Yˆ (t) dW(t).
h i
Define the process
t
S˜ (t) := 2Yˆ (s)[σ−1 (s)βˆ (s) − θ(s)Yˆ (s)]′dW(s).
0
Z
10

˜
Following a similar argument as in the proof of Theorem 3, we know S is a martingale.
Yˆ (T)2
Taking expectation of , we have
2a
Yˆ (T)2
E :=
2a
" #
′
σ−1(t)βˆ θ(t)Yˆ σ−1(t)βˆ θ(t)Yˆ
yˆ2 T r(t)Yˆ (t)2 (t) − (t) (t) − (t)
E + E − + dt .
2a  a (cid:16) (cid:17)2a(cid:16) (cid:17) 
0
(cid:20) (cid:21) Z (cid:20) (cid:21)
 
 
Define the set
ˆ ˆ
Π := (ω,t) ∈ Ω × [0,T] : Y (t) = 0,β(t) 6= 0 .
n o
P ˆ
We must have ( ⊗ Leb)(Π) = 0, otherwise, we may replace β(t) by 0 on the set Π and keep
ˆ
the same β(t) on the complement of Π, then we get the dual value strictly less than the one
ˆ ˆ
using β(t) everywhere, which is a contradiction to the optimality of β(t).
ˆ ˆ ˆ
Let β(t) = γˆ(t)Y (t) for t ∈ [0,T]. Then Y follows the SDE
dYˆ (t) = −r(t)Yˆ (t)dt + σ−1(t)γˆ(t) − θ(t) ′ Yˆ (t)dW(t)
ˆ
Y (0) = yˆ.
(cid:26) (cid:2) (cid:3)
ˆ ˆ
Hence, we have Y (t) = yˆH(t), where
t
1
Hˆ (t) := exp −r(s) − σ−1 (s)γˆ(s) − θ(s) ′ σ−1 (s)γˆ(s) − θ(s) ds
2
0
(cid:18)Z (cid:20) (cid:21)
(cid:0) (cid:1) (cid:0) (cid:1)
′
+ σ−1 (s)γˆ(s) − θ(s) dW(s) .
(cid:19)
(cid:2) (cid:3)
Let Γ satisfy the linear SDE
dΓ(t) = Γ(t)[−r(t)dt − θ′ (t)dW(t)], Γ(0) = 1.
By Theorem 9, also noting Γ(t)pˆ (t) is a martingale, we obtain
2
ˆ ˆ
Y (T) H(T)
pˆ (0) = E [Γ(T)pˆ (T)] = E −Γ(T) = −yˆE Γ(T) = x ,
2 2 0
a a
" # " #
which implies
x
0
yˆ = − .
ˆ
Γ(T)H(T)
E
a
" #
Moreover, we have
Yˆ(T) Hˆ(T)
pˆ (t) = Γ(t)−1E −Γ(T) F = −yˆΓ(t)−1E Γ(T) F ,
2 t t
a a
" # " #
(cid:12) (cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12)
P
which shows that pˆ (t) 6= 0 -a.e. for t ∈ [0(cid:12),T]. (cid:12)
2
ˆ P
Suppose x > 0, then Y (t) < 0 and pˆ (t) > 0 for ∀t ∈ [0,T], -a.e. Define
0 2
ˆ
Y (t) pˆ (t)
1
P (t) := − = − , ∀t ∈ [0,T].
+
pˆ (t) Xˆ (t)
2
11

Applying Ito’s formula, we have
πˆ′(t) π′(t)σ(t)qˆ (t) P (t)π′(t)σ(t)σ′(t)π(t)
1 +
dP (t) = −2r(t)P (t) − P (t) σ(t)θ(t) + + dt
+ + +
Xˆ (t) Xˆ (t)2 Xˆ (t)2
" #
′
qˆ (t) π(t)
+ − 1 − P (t)σ′ (t) dW(t),
+
ˆ ˆ
X(t) X(t)#
"
= −2r(t)P (t) − ξˆ′ (t)(σ(t)θ(t)P (t) + σ(t)Λ (t)) dt + Λ′ (t)dW(t), (4.4)
+ + + + +
h i
where
qˆ (t) P (t)σ′(t)π(t) πˆ(t)
1 + ˆ
Λ (t) := − − , ξ (t) := .
+ +
ˆ ˆ ˆ
X(t) X(t) X(t)
Define
H (t,v,P,Λ) :=v′Pσ(t)σ′ (t)v + 2v′ [σ(t)θ(t)P + σ(t)Λ],
+
H∗ (t,P,Λ) := inf H (t,v,P,Λ).
+ +
v∈K
We have
πˆ(t)
∂ H (t,ξˆ (t),P (t),Λ (t)) =2 P (t)σ(t)σ′ (t) + σ(t)θ(t)P (t) + σ(t)Λ (t)
v + + + + + + +
ˆ
X(t)
" #
qˆ (t) pˆ (t)
1 1
=2 −σ(t) − σ(t)θ(t) .
ˆ ˆ
X(t) X(t)#
"
Recall that by Theorem 3, we have
[πˆ(t) − π]′ [pˆ (t)σ(t)θ(t) + σ(t)qˆ (t)] ≥ 0 (4.5)
1 1
P ˆ
for ( ⊗ Leb)-a.e. (ω,t) ∈ Ω×[0,T] and π ∈ K. According to Theorem 11, X(t) = pˆ (t) > 0.
2
Dividing both sides of (4.5) by Xˆ (t)2, we obtain that
[ξˆ (t) − ξ]′∂ H (t,ξˆ (t),P (t),Λ (t)) ≤ 0
+ v + + + +
P
for ( ⊗ Leb)-a.e. (ω,t) ∈ Ω × [0,T] and ξ ∈ K. By [7, Proposition 2.2.1], we conclude that
H∗ (t,P (t),Λ (t)) = H (t,ξˆ (t),P (t),Λ (t)) ∀t ∈ [0,T], P − a.e. (4.6)
+ + + + + + +
Moreover, by [6, Page 52, Corollary], we have
0 ∈ P (t)σ(t)σ′ (t)ξˆ (t) + σ(t)[θ(t)P (t) + Λ (t)] + N (ξˆ (t)), ∀t ∈ [0,T] P -a.e.
+ + + + K +
where N (x) := {p ∈ RN : p′(x∗ − x) ≤ 0,∀x∗ ∈ K}, the normal cone of K at x ∈ K. For
K
all p ∈ N (x), since K is a cone, by choosing x∗ = 2x and x∗ = 1x, we have p′x ≤ 0 and
K
2
−1p′x ≤ 0, which gives p′x = 0. Therefore
2
ξˆ′ (t)P (t)σ(t)σ′ (t)ξˆ (t) + ξˆ′ (t)σ(t)[θ(t)P (t) + Λ (t)] = 0. (4.7)
+ + + + + +
Substituting (4.7) into (4.6), we obtain
H∗ (t,P (t),Λ (t)) = ξˆ′ (t)[σ(t)θ(t)P (t) + σ(t)Λ (t)] ∀t ∈ [0,T]. (4.8)
+ + + + + +
12

Substituting (4.8) back into (4.4), we have that P is the solution to the following nonlinear
+
BSDE
dP (t) = − 2r(t)P (t) + H∗ (t,P (t),Λ (t)) dt + Λ′ (t)dW(t),
+ + + + + +
P (T) = a, (4.9)
+
 (cid:2) (cid:3)
P (t) > 0. ∀t ∈ [0,T].
 +
ˆ P
Similarly, ifx < 0, then Y (t) > 0 and pˆ (t) < 0 for t ∈ [0,T], -a.e. Define
0 2
ˆ
Y (t) pˆ (t)
1
P (t) := − = − , ∀t ∈ [0,T].
−
pˆ (t) Xˆ (t)
2
Using a similar approach, it can be shown that P is the solution to the following nonlinear
−
BSDE
dP (t) = − 2r(t)P (t) + H∗ (t,P (t),Λ (t)) dt + Λ′ (t)dW(t),
− − − − − −
P (T) = a, (4.10)
−
 (cid:2) (cid:3)
P (t) > 0, ∀t ∈ [0,T].
 −
where 
H (t,v,P,Λ) :=v′Pσ(t)σ′ (t)v − 2v′ [σ(t)θ(t)P + σ(t)Λ],
−
H∗ (t,P,Λ) := inf H (t,v,P,Λ).
− −
v∈K
We find that (4.9) and (4.10) are the extended SRE introduced in [8]. Through the dual
approach, we have obtained an explicit representation of the unique solution to the SREs
in terms of the optimal state and adjoint processes. Finally, according to Theorem 9 we
conclude that the optimal solution to the primal problem is given by
πˆ′(t) = [σ′]−1(t)qˆ (t),
2
1 1
ˆ ˆ {x0>0} {x0<0}
 X(t) = pˆ (t) = −Y (t) + .
2
P (t) P (t)
 + −
(cid:20) (cid:21)
=RN βˆ
Remark 15. If K , then we must have the optimal control (t) = 0, which leads to
ˆ
γˆ(t) = 0 and H(t) = Γ(t) for t ∈ [0,T] a.e. Condition (4.5) is equivalent to
pˆ (t)θ(t) + qˆ (t) = 0.
1 1
ˆ
Replacing pˆ (t) and qˆ (t) by P (t), Λ (t) and ξ (t), we have
1 1 + + +
Λ (t)
σ′ (t)ξˆ (t) + θ(t) + + = 0.
+
P (t)
+
BSDE (4.4) (or (4.9)) becomes
Λ′ (t)Λ (t)
dP (t) = −2r(t)P (t) + 2θ′ (t)Λ (t) + θ′ (t)θ(t)P (t) + + + dt + Λ′ (t)dW(t),
+ + + + +
P (t)
+
(cid:20) (cid:21)
which is the SRE introduced in [22]. Using the duality approach, we obtain an explicit
representation of the unique solution to the SRE.
13

4.2 Deterministic coefficient case
RN
Assume K ⊂ is a closed convex cone and r,b,σ are deterministic functions and a > 0 is
a constant. In this case, the dual problem can be written as
Y (T)2
Minimize x y + E
0
2a
(cid:20) (cid:21)
over (y,β) ∈ R × H2(0,T;RN ) and Y satisfies the SDE (2.8) with α(t) = 0 and β(t) ∈ K0
for t ∈ [0,T] a.e., where K0 := {β : β′π ≤ 0,∀π ∈ K}, the polar cone of K. We solve the
ˆ
above problem in two steps: first, fix y and find the optimal control β(y); second, find the
optimal yˆ. We can then construct the optimal solution explicitly.
Step 1: Consider the associated HJB equation:
v (s,y) − r(s)yv (s,y) + 1 inf |σ−1(s)β − θ(s)y|2v (s,y) = 0,
t y β∈K0 yy
2
(4.11)
( v(T,y) = y2,
R
for each (s,y) ∈ [t,T] × . The infimum term in (4.11) can be written explicitly as
1. If y = 0, then it is trivial to obtain that
inf |σ−1 (s)β − θ(s)y|2 = inf |σ−1 (s)β|2 = 0.
β∈K0 β∈K0
2. If y > 0, then we have
2
β
inf |σ−1 (s)β − θ(s)y|2 = y2 inf σ−1 (s) − θ(s)
β∈K0 β∈K0 y
(cid:12) (cid:18) (cid:19) (cid:12)
(cid:12) 2 (cid:12)
(cid:12) (cid:12)
= y2 inf (cid:12) σ−1 (s)β¯ − θ(s) (cid:12)
yβ¯ ∈K0
(cid:12) (cid:12)
(cid:12) (cid:12)
= y2 |σ−1 (s)β (s) − θ(s)|2,
(cid:12) + (cid:12)
(cid:12) (cid:12)
where β (s) := argmin |σ−1(s)β − θ(s)|2.
+ β∈K0
3. If y < 0, then similarly we have
2
β
inf |σ−1 (s)β − θ(s)y|2 =y2 inf σ−1 (s) − θ(s)
β∈K0 β∈K0 y
(cid:12) (cid:12)
(cid:12) (cid:12)2
(cid:12) (cid:12)
=y2 inf (cid:12)σ−1 (s)β¯ + θ(s) (cid:12)
β¯ ∈K0
(cid:12) (cid:12)
(cid:12) (cid:12)
=y2 |σ−1 (s)β (s) + θ(s)|2,
(cid:12) − (cid:12)
(cid:12) (cid:12)
where β (s) := argmin |σ−1(s)β + θ(s)|2.
− β∈K0
Define
σ−1(s)β (s) − θ(s), if y > 0
+
σ(s,y) := σ−1(s)β (s) + θ(s), if y < 0
−

0, if y = 0.

The HJB equation (4.11) becomes

v (s,y) − r(s)yv (s,y) + 1y2|σ(s,y)|2v (s,y) = 0,
t y yy
2
v(T,y) = y2.
(cid:26)
14

According to the Feynman-Kac formula, we have
T 2
v(t,y) = E Y 2 (T)|Y (t) = y = y2eR t [−2r(s)+|σ(s,Y(s))| ]ds ,
(cid:2) (cid:3)
where the stochastic process Y follows the following geometric Brownian motion
dY (s) = −r(s)Y (s)ds + σ′ (s,Y (s))Y (s)dW(s), Y (t) = y.
Moreover, since Y follows a geometric Brownian motion and sign(Y (s)) = sign(y), ∀s ∈ [t,T],
we have
σ(s,Y (s)) = σ(s,y), ∀s ∈ [t,T].
In particular, we have
T 2
v(0,y) = y2eR 0 [−2r(s)+|σ(s,y)| ]ds . (4.12)
Step 2: Consider the following static optimization problem:
1
inf x y + v(0,y) (4.13)
0
y∈R 2a
Substituting (4.12) into the objective function, we obtain that problem (4.13) achieves min-
imum at
T 2
yˆ = −ax eR 0 [2r(s)−|σ(s,−x0)| ]ds .
0
Hence, we conclude that the optimal control is given by
T 2
ax eR t [2r(s)−|σ(s,−x0)| ]dsβ (t), if x > 0
0 − 0
βˆ (t) =  −ax eR tT [2r(s)−|σ(s,−x0)|2 ]dsβ (t), if x < 0
0 + 0



0, if x = 0.
0



ˆ ˆ
Using the dual optimal control (yˆ,β), we can find a solution (Y ,pˆ ,qˆ ) to the dual FBSDE
2 2
ˆ
(3.6) and (3.7), and then apply Theorem 9 to construct a solution (X,pˆ ,qˆ ) to the primal
1 1
FBSDE (3.2) and (3.3). Moreover, in this case we can construct a solution to the SREs (4.9)
and (4.10) explicitly as
T
Pˆ (t) = Pˆ (t) = aeR t [2r(s)+σ′(s,−x0)θ(s)]ds . (4.14)
+ −
Next, we verify that (4.14) are indeed solutions to the SREs (4.9) and (4.10) with Λ (t) = 0
+
and Λ (t) = 0, respectively. To this end, we consider the case x > 0 and y < 0. According
− 0
to Theorem 9, we have
ˆ
X(t) = pˆ (t),∀t ∈ [0,T],a.e.
2
Hence,
Γ(T)Y (T) Y (t) Γ(T)Y (T)
ˆ
X(t) = E − F = − E F , (4.15)
t t
aΓ(t) a Γ(t)Y (t)
(cid:20) (cid:12) (cid:21) (cid:20) (cid:12) (cid:21)
(cid:12) (cid:12)
where Γ follows the SDE (cid:12) (cid:12)
(cid:12) (cid:12)
dΓ(t) = Γ(t)[−r(t)dt − θ′ (t)dW(t)],∀t ∈ [0,T],Γ(0) = 1.
Applying Ito’s lemma, we obtain
dΓ(t)Y (t) = [−2r(t) − θ′ (t)σ(t,y)]Y (t)Γ(t)dt − [σ′ (t,y) + θ′ (t)]Y (t)Γ(t)dW(t). (4.16)
15

Combining (4.15) and (4.16), we have
Y (t) T
Xˆ (t) = − eR t [−2r(s)−θ′(s)σ(s,y)]ds .
a
ˆ
Applying Ito’s lemma again, we have X satisfies the SDE
dXˆ (t) = [r(t)Xˆ (t) + θ′ (t)σ(t,y)Xˆ (t)]dt + σ′ (t,y)Xˆ (t)dW(t). (4.17)
Comparing (4.17) with (2.3), we conclude that
πˆ′ (t) = σ′ (t,y)σ−1 (t)Xˆ (t),
which implies that
πˆ′(t)
ξˆ′ (t) = = σ′ (t,y)σ−1 (t). (4.18)
+ ˆ
X(t)
Substituting (4.18) back into (4.8), we have
H∗ (t,P (t),Λ (t)) = σ′ (t,y)θ(t)P (t).
+ + +
Taking x < 0 and following the same steps, we obtain
0
H∗ (t,P (t),Λ (t)) = σ′ (t,y)θ(t)P (t).
− − −
ˆ ˆ
Hence, we conclude that P (t) and P (t) defined in (4.14) are indeed solutions to SREs (4.9)
+ −
and (4.10).
5 Proofs of the Main Results
In this section we give proofs of the main results in Section 3.
Proof of Theorem 3. Since the cost functional J is convex, according to [7, Proposition 2.2.1],
a necessary and sufficient condition for πˆ to be optimal is that
hJ′ (πˆ),πˆ − πi ≤ 0, ∀π ∈ A, (5.1)
where J′(πˆ) is the Gaˆteaux-dirivative of J at πˆ and can be computed explicitly as (2.3) is a
linear SDE and J is a quadratic functional. The optimality condition (5.1) can be written
as
T
E Q(t)Xπˆ (t) Xπˆ (t) − Xπ (t) + S′ (t) πˆ(t) Xπˆ (t) − Xπ (t) + (πˆ(t) − π(t))Xπˆ (t)
0
(cid:20)Z (cid:20)
(cid:16) (cid:17) (cid:16) (cid:16) (cid:17) (cid:17)
+ πˆ′ (t) − π′ (t) R(t)πˆ(t) dt + aXπˆ (T) + c Xπˆ (T) − Xπ (T) ≤ 0, (5.2)
(cid:21) (cid:21)
h i(cid:16) (cid:17)
(cid:0) (cid:1)
for all π ∈ A. Applying Ito’s formula to Xπˆ(t)pˆ (t), we have
1
d(Xπˆ (t)pˆ (t)) = pˆ (t)πˆ′ (t)σ(t)θ(t) + πˆ′ (t)σ(t)qˆ (t) + Q(t)Xπˆ (t)2 + S′ (t)Xπˆ (t)πˆ(t) dt
1 1 1
h i
+ pˆ (t)πˆ′ (t)σ(t) + qˆ′ (t)Xπˆ (t) dW(t). (5.3)
1 1
h i
˜
Define the process S as
t
S˜ (t) := pˆ (s)πˆ′ (s)σ(s) + qˆ′ (s)Xπˆ (s) dW(s), 0 ≤ t ≤ T.
1 1
0
Z
(cid:16) (cid:17)
16

˜ ˜
Obviously, S is a local martingale. To prove that S is a true martingale, it is sufficient to
˜
show that E sup |S(s)| < ∞. According to the Burkholder-Davis-Gundy inequality
0≤s≤T
[9, Theorem 3h.3.28], it is suffiicient to verify that
1
T 2
E [|pˆ (s)π′ (s)σ(s)|2 + |qˆ (s)Xπˆ (s)|2 ]ds < ∞.
1 1
 
0
(cid:18)Z (cid:19)
 
Xπˆ S2(0,T;R
Note that from [13, Corollary 2.5.10], we have that ∈ ). Combining with
S2(0,T;R H2(0,t;RN
p ∈ ) and q ∈ ) and by H¨oder’s inequality, we have
1 1
1
T 2
E [|pˆ (s)π′ (s)σ(s)|2 + |qˆ (s)Xπˆ (s)|2 ]ds
1 1
 
0
(cid:18)Z (cid:19)
  1
T T 2
≤ E sup |pˆ (s)|2 |π′ (s)σ(s)|2ds + sup |Xπˆ (s)|2 |q (s)|2ds
1 1
 
 0≤s≤T 0 0≤s≤T 0 !
Z Z
 
T T
1 1 1 1
≤ E sup |pˆ (s)|2 + E |π′ (s)σ(s)|2ds + E sup |Xπˆ (s)|2 + E |qˆ (s)|2ds
1 1
2 2 2 2
"0≤s≤T # 0 "0≤s≤T # 0
(cid:20)Z (cid:21) (cid:20)Z (cid:21)
< ∞,
which implies that S˜ is a true martingale. Taking expectation of Xπˆ(T)pˆ (T), we have
1
T
E Xπˆ (T)pˆ (T) = x pˆ (0) + E pˆ (t)πˆ′ (t)σ(t)θ(t) + πˆ′ (t)σ(t)qˆ (t) (5.4)
1 0 1 1 1
0
(cid:20)Z (cid:20)
h i
+ Q(t)Xπˆ (t)2 + S′ (t)Xπˆ (t)πˆ(t) dt
(cid:21) (cid:21)
Similarly, applying Ito’s formula to Xπ (t)pˆ (t) and taking expectation, we obtain that
1
T
E [Xπ (T)pˆ (T)] = x pˆ (0) + E pˆ (t)π′ (t)σ(t)θ(t) + π′ (t)σ(t)qˆ (t) (5.5)
1 0 1 1 1
0
(cid:20)Z (cid:20)
+ Q(t)Xπˆ (t)Xπ (t) + S′ (t)Xπ (t)πˆ(t) dt
(cid:21) (cid:21)
Combining (5.2),(5.4) and (5.5), we obtain that πˆ ∈ A is an optimal control of the primal
problem if and only if
T
E πˆ′ (t) − π′ (t) pˆ (t)σ(t)θ(t) + σ(t)qˆ (t) + S(t)Xπˆ (t) + R(t)πˆ(t) dt ≥ 0 (5.6)
1 1
0
(cid:20)Z (cid:21)
h i
(cid:2) (cid:3)
R RN R
for all π ∈ A. Define the Hamiltonian function H : Ω × [0,T] × × → as
1
H(ω,t,x,π) := π′ pˆ (t)σ(t)θ(t) + σ(t)qˆ (t) + S(t)x + R(t)π
1 1
2
(cid:20) (cid:21)
and define the set-valued map F : Ω × [0,T] → K as
F(ω,t) := π ∈ K : πˆ′ (t) − π′ H ω,t,Xπˆ (t),πˆ(t) ≥ 0 .
π
n (cid:16) (cid:17) o
(cid:2) (cid:3)
Then F is a measurable set-valued map, see [1, Definition 8.1.1]. Given π ∈ K, define the
Bπ
set as
Bπ := (ω,t) ∈ Ω × [0,T] : πˆ′ (t) − π′ H (t,Xπˆ (t),πˆ(t)) < 0 .
π
n o
(cid:2) (cid:3)
17

Bπ
According to [1, Theorem 8.14], ∈ F for t ∈ [0,T]. Define an adapted control π˜ :
t t
Ω × [0,T] → K as
Bπ
π if (ω,t) ∈
π˜(ω,t) :=
πˆ(ω,t), otherwise.
(cid:26)
(P Leb)(Bπ
Suppose that ⊗ ) > 0, then
T
E [πˆ′ (t) − π˜′ (t)]H (t,Xπˆ (t),πˆ(t))dt < 0,
π
0
(cid:20)Z (cid:21)
(P Leb)(Bπ
contradicting with (5.6). Hence, we conclude that ⊗ ) = 0 for any fixed π ∈ K.
Moreover, since K is separable, we conclude that
[πˆ′ (t) − π′ ]H (t,Xπˆ (t),πˆ(t)) ≥ 0, ∀π ∈ K
π
P (cid:3)
for ( ⊗ Leb)-a.e. (ω,t) ∈ Ω × [0,T].
Proof of Theorem 7. Let (yˆ,αˆ,βˆ ) be optimal for the dual problem and (Y (yˆ,αˆ,βˆ ),pˆ ,qˆ )
2 2
satisfy (3.6). Let (y,α,β) ∈ B and Y (y,α,β) satisfy the SDE (2.8). Applying Ito’s formula to
pˆ (t)Y (y,α,β)(t), we have
2
d(pˆ (t)Y (y,α,β) (t)) = α(t)pˆ (t) + qˆ′ (t)σ−1 (t)β(t) dt
2 2 2
′
(cid:2) + qˆ′ (t)Y (y,α,β) (t) + σ−1 (t(cid:3) )β(t) − θ(t)Y (y,α,β) (t) pˆ (t) dW(t).
2 2
(cid:20) (cid:21)
(cid:16) (cid:17)
It can be shown, following a similar argument as in the proof of Theorem 3, that the process
t
qˆ′ (s)Y (y,α,β) (s) + (σ−1 (s)β(s) − θ(s)Y (y,α,β) (s))′pˆ (s) dW(s), 0 ≤ t ≤ T,
2 2
0
Z
h i
is a martingale. Taking the expectation of pˆ (T)Y (y,α,β)(T), we obtain
2
T
E pˆ (T)Y (y,α,β) (T) = pˆ (0)y + E α(t)pˆ (t) + qˆ′ (t)σ−1 (t)β(t) dt . (5.7)
2 2 2 2
0
(cid:20)Z (cid:21)
h i
(cid:2) (cid:3)
For ε > 0 define (yε,αε,βε ) ∈ B by
ε ε ε ˆ
(y ,α ,β ) = (yˆ,αˆ,β) + ε(y,α,β).
Then
Y (yε ,αε ,βε ) (t) = Y (yˆ,αˆ,βˆ ) (t) + εY (y,α,β) (t).
ˆ
Since (yˆ,αˆ,β) is optimal, we have
1
ε ε ε ˆ
Ψ(y ,α ,β ) − Ψ(yˆ,αˆ,β) ≥ 0.
ε
h i
(yˆ,αˆ,βˆ
Y )(T) + c
Substituting (2.7) into the above inequality, also noting pˆ (T) = − , we get
2
a
Y (y,α,β)(T)2
yx − E Y (y,α,β)(T)pˆ (T) + εE
0 2
2a
" #
(5.8)
T(cid:2) (cid:3)
1
ε ε ˆ
+ E φ(α (t),β (t)) − φ(αˆ(t),β(t)) dt ≥ 0.
ε
0
(cid:20)Z (cid:21)
h i
18

Combining (5.8) with (5.7) and then letting ε ↓ 0, we have
T
y (x − pˆ (0)) + limE [g˜(t,ε) − qˆ′ (t)σ−1 (t)β(t) − α(t)pˆ (t)]dt ≥ 0,
0 2 2 2
ε↓0
0
(cid:20)Z (cid:21)
1
where g˜(ω,t,ε) = (φ(t,αε (t),βε (t)) − φ(t,αˆ(t),βˆ (t))). Let α(t) = 0 and β(t) = 0 for
ε
t ∈ [0,T], we get
R
y(x − pˆ (0)) ≥ 0, ∀y ∈ .
0 2
Hence, pˆ (0) = x . Recall that the function f in (2.4) is convex and the set K is convex,
2 0
ˆ
according to [17, Theorem 26.3], φ has directional derivative at (αˆ(t),β(t)) in any direction
P
( ⊗ Leb) a.e. on Ω × [0.T]. Since ε → g˜(ω,t,ε) is a nondecreasing function, Assumption 5
and the monotone convergence theorem imply that
T
E φo t,αˆ(t),βˆ (t);α(t),β(t) − qˆ′ (t)σ−1 (t)β(t) − α(t)pˆ (t) dt ≥ 0 (5.9)
2 2
0
(cid:20)Z (cid:21)
h (cid:16) (cid:17) i
where
ˆ ˆ
φ(t,αˆ + εα,β + εβ) − φ(t,αˆ,β)
o ˆ
φ ω,t,αˆ,β;α,β := lim .
ε
ε↓0
(cid:16) (cid:17)
R RN B(α,β)
For (α,β) ∈ × , define the set as
B(α,β) := (ω,t) ∈ Ω × [0,T] : φo αˆ(t),βˆ (t);α,β − qˆ′ (t)σ−1 (t)β − αpˆ (t) < 0 .
2 2
n (cid:16) (cid:17) o
B(α,β)
Using a similar argument as in the proof of Theorem 3, we conclude that ∈ F for
t t
(P Leb)(B(α,β)) R RN
t ∈ [0,T] and ⊗ = 0 for all (α,β) ∈ × . Equivalently, given any
R RN
(α,β) ∈ × ,
φo αˆ(t),βˆ (t);α,β − qˆ′ (t)σ−1 (t)β − αpˆ (t) ≥ 0,
2 2
(cid:16) (cid:17)
(P RN+1,
for ⊗ Leb)-a.e. (ω,t) ∈ Ω × [0,T]. In addition, by the separability of the space we
conclude that
φo αˆ(t),βˆ (t);α,β − qˆ′ (t)σ−1 (t)β − αpˆ (t) ≥ 0,∀(α,β) ∈ R × RN
2 2
(cid:16) (cid:17)
P
for ( ⊗ Leb)-a.e. (ω,t) ∈ Ω × [0,T]. By the definition of Clarke’s generalized gradient [6,
Chapter 2], the above condition can be written as
pˆ (t),[σ′ ]−1 (t)qˆ (t) ∈ ∂φ αˆ(t),βˆ (t) .
2 2
(cid:16) (cid:17)
(cid:0) (cid:1)
π′βˆ f˜
According to [17, Theorem 23.5] , we conclude that xαˆ(t) + (t) − (t,x,π) achieves the
supreme at (pˆ (t),[σ′]−1(t)qˆ (t)) for (P ⊗ Leb)-a.e. (ω,t) ∈ Ω × [0,T], which implies
2 2
[σ′ ]−1 (t)qˆ (t) ∈ K,
2
P
for ( ⊗ Leb)-a.e. (ω,t) ∈ Ω × [0,T]. We have proved the necessary condition.
Let (yˆ,αˆ,βˆ ) ∈ B be an admissible control to the dual problem with processes Y (yˆ,αˆ,βˆ ),pˆ ,qˆ
2 2
satisfying the FBSDE (3.6) and conditions (3.7). Define the Hamiltonian f(cid:16)unction H : (cid:17)
R RN R
Ω × [0,T] × × → as
H(ω,t,α,β) = qˆ′ (t)σ−1 (t)β + αpˆ (t) − φ(t,α,β).
2 2
19

By condition (3.7) and the classical result in duality theorem, we have
ˆ
(0,0) ∈ ∂H αˆ(t),β(t) , (5.10)
(cid:16) (cid:17)
P B
for ( ⊗ Leb)-a.e. (ω,t) ∈ Ω × [0,T]. Given any admissible control (y,α,β) ∈ , define
˜ ˆ
y˜ = y − yˆ, α˜ = α − αˆ, β = β − β.
Let Y (y,α,β) and Y (y˜,α˜,β˜ ) be the associated state processes satisfying the SDE (2.8). According
to the definition of the dual problem, also noting m is a convex function, we have
T
(yˆ,αˆ,βˆ
Y )(T) + c
Ψ(y,α,β) − Ψ yˆ,αˆ,βˆ ≥y˜x + E Y (y˜,α˜,β˜ ) (T)
0
a
" #
(cid:16) (cid:17)
T
ˆ
+ E φ(t,α(t),β(t)) − φ(t,αˆ(t),β(t)) dt .
0
(cid:20)Z (cid:21)
h i
(yˆ,αˆ,βˆ
Y ) + c
Replacing with −pˆ (T) in the above inequality, we have
2
a
T
Ψ(y,α,β) − Ψ yˆ,αˆ,βˆ ≥y˜(x − pˆ (0)) + E qˆ′ (t)σ−1 (t)β˜ (t) − α˜(t)qˆ (t) dt
0 2 2 2
0
(cid:20)Z (cid:21)
(cid:16) (cid:17) h i
T
ˆ
+ E φ(t,α(t),β(t)) − φ(t,αˆ(t),β(t)) dt
0
(cid:20)Z (cid:21)
h i
T
ˆ
=E −H(t,α(t),β(t)) + H(t,αˆ(t),β(t)) dt .
0
(cid:20)Z (cid:21)
h i
According to condition (5.10) and the concavity of H, we conclude that
¯ ˆ
Ψ y¯,α¯,β − Ψ yˆ,αˆ,β ≥ 0.
(cid:16) (cid:17)
(cid:0) (cid:1)
B (cid:3)
Since (y,α,β) ∈ is arbitrary, we have proved the sufficient condition.
ˆ B
Proof of Theorem 9. Suppose that (yˆ,αˆ,β) ∈ is optimal for the dual problem. By Theorem
(yˆ,αˆ,βˆ
7, the process Y )(t),pˆ (t),qˆ (t) solves the dual FBSDE (3.6) and satisfies condition
2 2
(3.7). Define πˆ(cid:16)(t) and (Xπˆ(t),pˆ (t),qˆ(cid:17)(t)) as in (3.8) and (3.9), respectively. According to
1 1
P
Theorem 7 and condition (3.7), we have πˆ(t) ∈ K -a.s. and
Xπˆ αˆ(t),βˆ
(t),πˆ(t) ∈ ∂φ (t) .
(cid:16) (cid:17) (cid:16) (cid:17)
The classical result in duality theory implies
αˆ(t),βˆ ∂f˜ Xπˆ
(t) ∈ (t),πˆ(t) .
(cid:16) (cid:17) (cid:16) (cid:17)
˜
Recall that f(ω,t,x,π) = f(ω,t,x,π) + Ψ (π), we can get
K
αˆ(t) = Q(t)Xπˆ (t) + S′ (t)πˆ(t), (5.11)
βˆ S(t)Xπˆ
(t) ∈ (t) + R(t)πˆ(t) + ∂Φ (πˆ(t)) (5.12)
K
P
for ( ⊗ Leb)-a.e. (ω,t) ∈ Ω × [0,T]. Combining (3.8), (3.9) and (5.11), we obtain that
Xπˆ,pˆ ,qˆ solves the primal FBSDE (3.2). Moreover, combining (3.9) and (5.12) gives
1 1
(cid:0) (cid:1)
20

condition (3.3). Using the sufficient condition for optimality in Theorem 3, we conclude that
(cid:3)
πˆ is indeed an optimal control for the primal problem.
Proof of Theorem 11. Suppose that πˆ ∈ A is an optimal control for the primal problem. By
Theorem 3, the process Xπˆ(t),pˆ (t),qˆ (t) solves the FBSDE (3.2) and satisfies condition
1 1
(3.3). Define (yˆ,αˆ(t),βˆ (t)) and (Y (yˆ,αˆ,βˆ )(t),pˆ (t),qˆ (t)) as in (3.10) and (3.11), respectively.
(cid:0) (cid:1) 2 2
(yˆ,αˆ,βˆ
Substituting them into the primal FBSDE (3.2), we obtain that Y ),pˆ ,qˆ satisfies
2 2
the dual FBSDE (3.6). By the construction in (3.10) and (3.11), th(cid:16)e first two con(cid:17)ditions in
(3.7) are satisfied. In addition, by condition (3.3) and the concavity of H, we have
βˆ f˜ Xπˆ
(t) ∈ ∂ (t),πˆ(t) .
π
(cid:16) (cid:17)
Consequently, we have
αˆ(t),βˆ ∂f˜ Xπˆ
(t) ∈ (t),πˆ(t) ,
(cid:16) (cid:17) (cid:16) (cid:17)
ˆ
which is equivalent to the third condition in (3.7). By Theorem 7, we conclude that yˆ,αˆ,β
(cid:3)
is indeed an optimal control to the dual problem. (cid:16) (cid:17)
6 Conclusion
In this paper, we discuss a continuous-time constrained quadratic risk minimization problem
with random market coefficients. Following a convex duality approach, we derive the neces-
sary and sufficient optimality conditions for primal and dual problems in terms of FBSDEs
plus additional conditions. We establish an explicit connection between primal and dual
problems in terms of their associated forward backward systems. We prove that the optimal
controls of primal and dual problems can be written as functions of adjoint processes of
their counterpart. Moreover, we also find that the optimal state processes for both problems
coincide with the optimal adjoint processes of their counterpart. We solve cone-constrained
quadratic risk minimization problems using the dual approach. We recover the solutions
to the extended SREs introduced in the literature from the optimal solutions to the dual
problem and find the closed-form solutions to the extended SREs when the coefficients are
deterministic. There are still many open questions. For example, can the results be extended
to incomplete market models (not a complete market model as in the paper)? Can the dual
problem be solved for a bounded control set K (not a cone)? Can solutions be found to the
primal and dual FBSDEs with random coefficients (not deterministic coefficients)? We leave
these outstanding problems in future works.
Acknowledgments. The authors are grateful to three anonymous reviewers whose con-
structive comments and suggestions have helped to improve the paper of the previous ver-
sion.
References
[1] J-P. Aubin and H. Frankowska, Set-Valued Analysis, Birkh¨auser, 1990.
[2] J. M. Bismut, Conjugate convex functions in optimal stochastic control, J. Math. Anal.
Appl., 44 (1973), pp. 384–404.
[3] A. Cadenillas and I. Karatzas, The stochastic maximum principle for linear convex opti-
mal control with random coefficients, SIAM J. Control Optim., 33 (1995), pp. 590–624.
21

[4] C. Czichowsky and M. Schweizer, Convex duality in mean-variance hedging under convex
trading constraints, Adv. in Appl. Probab., 44 (2012), pp. 1084–1112.
[5] C. Czichowsky, N. Westray and H Zheng, Convergence in the semimartingale topology
and constrained portfolios, Seminaire de Probabilities, XLIII (2011), pp. 395–412.
[6] F. H. Clarke, Optimization and Nonsmooth Analysis, SIAM, 1990.
[7] I. Ekeland and R. Tamam, Convex Analysis and Variational Problems, SIAM, 1987.
[8] Y. Hu and X. Y. Zhou, Constrained stochastic lq control with random coefficients, and
application to portfolio selection, SIAM J. Control Optim., 44 (2005), pp. 444–446.
[9] I. Karatzas and S. E. Shreve, Brownian Motion and Stochastic Calculus, Springer, 1998.
[10] I. Karatzas and S. E. Shreve, Methods of Mathematical Finance, Springer, 2001.
[11] D. Kramkov and W. Schachermayer, The asymptotic elasticity of utility functions and
optimal investment in incomplete markets, Ann. Appl. Probab., 9 (1999), pp. 904–950.
[12] D. Kramkov and W. Schachermayer, Necessary and sufficient conditions in the problem
of optimal investment in incomplete markets, Ann. Appl. Probab., 13 (2003), pp. 1504–
1516.
[13] N. V. Krylov, Controlled Diffusion Processes, Springer-Verlag, 1980.
[14] C. Labb´e and A. J. Heunis, Convex duality in constrained mean-variance portfolio op-
timization, Adv. in Appl. Probab., 39 (2007), pp. 77–104.
[15] B. Øksendal and A. Sulem, A stochastic control approach to robust duality in utility
maximization, preprint (2013), available at http://arxiv.org/abs/1304.5040.
[16] H. Pham, Continuous-time Stochastic Control and Optimization with Financial Appli-
cations, Springer, 2009.
[17] R. T. Rockafeller, Convex Analysis, Princeton University Press, 1970.
[18] L. C. G. Rogers, Duality in constrained optimal investment and consumption problems:
a synthesis, in Paris-Princeton Lectures on Mathematical Finance, Springer, Berlin, 2002,
pp. 95-131.
[19] M. Schweizer, Mean-variance hedging, Encyclopedia of Quantitative Finance, 2010, pp.
1177-1181.
[20] J. Yong, Linear forward-backward stochastic differential equations with random coeffi-
cients, Probab. Theory Related Fields, 135 (2006), pp. 53–83.
[21] J. Yong and X.Y. Zhou, Stochastic Controls: Hamiltonian Systems and HJB Equations,
Springer, 1999.
[22] X. Y. Zhou and A. Lim, Mean-variance portfolio selection with random parameters in a
complete market, Math. Oper. Res., 27 (2002), pp. 101–120.
22